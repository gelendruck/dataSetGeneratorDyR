{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# baseline cnn model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from os import listdir\n",
    "import os, sys\n",
    "from IPython.display import display\n",
    "from IPython.display import Image as _Imgdis\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "    folder = \"C:/Users/Dani/data/images/\"\n",
    "    onlyfiles = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "    \n",
    "    train_files = []\n",
    "    y_train = []\n",
    "    i=0\n",
    "    for _file in onlyfiles:\n",
    "        train_files.append(_file)\n",
    "\n",
    "    image_width = 1000\n",
    "    image_height = 800\n",
    "    ratio = 2\n",
    "\n",
    "    image_width = int(image_width / ratio)\n",
    "    image_height = int(image_height / ratio)\n",
    "\n",
    "    channels = 3\n",
    "    nb_classes = 1\n",
    "\n",
    "    dataset = np.ndarray(shape=(len(train_files), channels, image_height, image_width),\n",
    "                         dtype=np.float32)\n",
    "    i = 0\n",
    "    for _file in train_files:\n",
    "        img = load_img(folder + \"/\" + _file)  # this is a PIL image\n",
    "        img.thumbnail((image_width, image_height))\n",
    "        # Convert to Numpy Array\n",
    "        x = img_to_array(img)  \n",
    "        x = x.reshape(-1, 3,400,500)\n",
    "        # Normalize\n",
    "#         x = (x - 128.0) / 128.0\n",
    "        dataset[i] = x\n",
    "        i += 1\n",
    "        if i % 100 == 0:\n",
    "            print(\"%d images to array\" % i)\n",
    "    print(\"All images to array!\")\n",
    "\n",
    "#    for i in dataset:\n",
    "#        print(i.size)\n",
    "    \n",
    "    z_train, y_train = np.loadtxt('C:/Users/Dani/labeled.txt', delimiter=' | ', unpack = True)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    #Splitting \n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset, y_train, test_size=0.4, random_state=0)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n",
    "    print(\"Train set size: {0}, Val set size: {1}, Test set size: {2}\".format(len(X_train), len(X_val), len(X_test)))\n",
    "    \n",
    "    from keras.utils import to_categorical\n",
    "    y_binary = to_categorical(y_train)\n",
    "    \n",
    "    #print(y_train)\n",
    "    #print(y_test)\n",
    "    #print(y_val)\n",
    "    \n",
    "    return X_train, y_binary, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_array = np.random.rand(3,2)\n",
    "# test_vector = np.random.rand(4)\n",
    "\n",
    "# np.savez_compressed('C:/Users/Dani/data/images', a = test_array, b = test_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(3, 400, 500)))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same', data_format=None))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(2, activation='softmax'))\n",
    "# \tcompile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels(trainX, testX)\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # fit model\n",
    "    model.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)\n",
    "    # save model\n",
    "    model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images to array\n",
      "200 images to array\n",
      "300 images to array\n",
      "400 images to array\n",
      "500 images to array\n",
      "600 images to array\n",
      "700 images to array\n",
      "800 images to array\n",
      "900 images to array\n",
      "1000 images to array\n",
      "1100 images to array\n",
      "1200 images to array\n",
      "1300 images to array\n",
      "1400 images to array\n",
      "1500 images to array\n",
      "1600 images to array\n",
      "1700 images to array\n",
      "1800 images to array\n",
      "1900 images to array\n",
      "2000 images to array\n",
      "2100 images to array\n",
      "2200 images to array\n",
      "2300 images to array\n",
      "2400 images to array\n",
      "2500 images to array\n",
      "2600 images to array\n",
      "2700 images to array\n",
      "2800 images to array\n",
      "2900 images to array\n",
      "3000 images to array\n",
      "3100 images to array\n",
      "3200 images to array\n",
      "3300 images to array\n",
      "3400 images to array\n",
      "3500 images to array\n",
      "3600 images to array\n",
      "3700 images to array\n",
      "3800 images to array\n",
      "3900 images to array\n",
      "4000 images to array\n",
      "4100 images to array\n",
      "4200 images to array\n",
      "4300 images to array\n",
      "4400 images to array\n",
      "4500 images to array\n",
      "4600 images to array\n",
      "4700 images to array\n",
      "4800 images to array\n",
      "4900 images to array\n",
      "5000 images to array\n",
      "5100 images to array\n",
      "5200 images to array\n",
      "5300 images to array\n",
      "5400 images to array\n",
      "5500 images to array\n",
      "5600 images to array\n",
      "5700 images to array\n",
      "5800 images to array\n",
      "5900 images to array\n",
      "6000 images to array\n",
      "6100 images to array\n",
      "6200 images to array\n",
      "6300 images to array\n",
      "6400 images to array\n",
      "6500 images to array\n",
      "6600 images to array\n",
      "6700 images to array\n",
      "6800 images to array\n",
      "6900 images to array\n",
      "7000 images to array\n",
      "7100 images to array\n",
      "7200 images to array\n",
      "7300 images to array\n",
      "7400 images to array\n",
      "7500 images to array\n",
      "7600 images to array\n",
      "7700 images to array\n",
      "7800 images to array\n",
      "7900 images to array\n",
      "8000 images to array\n",
      "8100 images to array\n",
      "8200 images to array\n",
      "8300 images to array\n",
      "8400 images to array\n",
      "8500 images to array\n",
      "8600 images to array\n",
      "8700 images to array\n",
      "8800 images to array\n",
      "8900 images to array\n",
      "9000 images to array\n",
      "9100 images to array\n",
      "9200 images to array\n",
      "All images to array!\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ac6c88879450>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# entry point, run the test harness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrun_test_harness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-8b0c249174de>\u001b[0m in \u001b[0;36mrun_test_harness\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun_test_harness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# load dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# prepare pixel data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_pixels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-c7df684b73b4>\u001b[0m in \u001b[0;36mload_dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;31m#Splitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Train set size: {0}, Val set size: {1}, Test set size: {2}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2123\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n\u001b[1;32m-> 2124\u001b[1;33m                                      safe_indexing(a, test)) for a in arrays))\n\u001b[0m\u001b[0;32m   2125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2123\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n\u001b[1;32m-> 2124\u001b[1;33m                                      safe_indexing(a, test)) for a in arrays))\n\u001b[0m\u001b[0;32m   2125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36msafe_indexing\u001b[1;34m(X, indices)\u001b[0m\n\u001b[0;32m    217\u001b[0m                                    indices.dtype.kind == 'i'):\n\u001b[0;32m    218\u001b[0m             \u001b[1;31m# This is often substantially faster than X[indices]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "\t# load the image\n",
    "\timg = load_img(filename, grayscale=False, target_size=(800, 1000))\n",
    "\t# convert to array\n",
    "\timg = img_to_array(img)\n",
    "\t# reshape into a single sample with 1 channel\n",
    "\timg = img.reshape(-1, 3,400,500)\n",
    "\t# prepare pixel data\n",
    "\timg = img.astype('float32')\n",
    "\timg = img / 255.0\n",
    "\treturn img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image and predict the class\n",
    "def run_example():\n",
    "\t# load the image\n",
    "\timg = load_image('sample_image_7.png')\n",
    "\t# load model\n",
    "\tmodel = load_model('final_model.h5')\n",
    "\t# predict the class\n",
    "\tdigit = model.predict_classes(img)\n",
    "\tprint(digit[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# entry point, run the example\n",
    "run_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
